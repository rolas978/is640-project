{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Ollama Chat Interface\n",
    "\n",
    "Interactive chat interface for your local Ollama Mistral model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Dependencies\n",
    "\n",
    "Run this cell first to install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "# !pip install ipywidgets requests --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Button, Box, VBox, HBox, Text, HTML as HTMLWidget, Textarea, Output\n",
    "\n",
    "# Configuration\n",
    "OLLAMA_URL = \"http://127.0.0.1:11434\"\n",
    "MODEL_NAME = \"mistral:7b\"\n",
    "# MODEL_NAME = \"gemma3:1b-it-qat\"\n",
    "\n",
    "# Chat history\n",
    "chat_history = []\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Endpoint: {OLLAMA_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Test Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_connection():\n",
    "    \"\"\"Test connection to Ollama.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{OLLAMA_URL}/api/tags\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ Successfully connected to Ollama!\")\n",
    "            models = response.json().get('models', [])\n",
    "            print(f\"\\nAvailable models: {len(models)}\")\n",
    "            for model in models:\n",
    "                print(f\"  - {model['name']}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Connection failed: Status {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"‚ùå Cannot connect to Ollama\")\n",
    "        print(\"\\nMake sure:\")\n",
    "        print(\"  1. Docker container is running: docker ps\")\n",
    "        print(\"  2. Port 11434 is mapped correctly\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return False\n",
    "\n",
    "check_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Chat Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to_ollama(prompt: str):\n",
    "    \"\"\"Send message to Ollama and get response.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OLLAMA_URL}/api/generate\",\n",
    "            json={\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            },\n",
    "            timeout=120\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()['response']\n",
    "        else:\n",
    "            return f\"Error: Status code {response.status_code}\"\n",
    "    \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return \"‚ùå Error: Cannot connect to Ollama. Is the container running?\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "def format_chat_message(role: str, message: str, timestamp: str = None):\n",
    "    \"\"\"Format a chat message as HTML.\"\"\"\n",
    "    if timestamp is None:\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    \n",
    "    if role == \"user\":\n",
    "        bg_color = \"#2b5278\"\n",
    "        icon = \"üë§\"\n",
    "        align = \"right\"\n",
    "    else:\n",
    "        bg_color = \"#1e3a5f\"\n",
    "        icon = \"ü§ñ\"\n",
    "        align = \"left\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "    <div style=\"margin: 10px 0; text-align: {align};\">\n",
    "        <div style=\"display: inline-block; max-width: 70%; background-color: {bg_color}; \n",
    "                    padding: 12px; border-radius: 10px; text-align: left;\">\n",
    "            <div style=\"font-size: 0.8em; color: #aaa; margin-bottom: 5px;\">\n",
    "                {icon} <strong>{role.upper()}</strong> <span style=\"float: right;\">{timestamp}</span>\n",
    "            </div>\n",
    "            <div style=\"color: #fff; white-space: pre-wrap; word-wrap: break-word;\">{message}</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "print(\"‚úÖ Chat functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Response Manually without Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_llm(prompt: str):\n",
    "    \"\"\"Send message to LLM and get a stream of live processed text.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OLLAMA_URL}/api/generate\",\n",
    "            json={\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            },\n",
    "            timeout=120,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"Response received successfully.\")\n",
    "            for line in response.iter_lines(decode_unicode=True):\n",
    "                if line:\n",
    "                    try:\n",
    "                        json_data = json.loads(line)\n",
    "                        if 'response' in json_data:\n",
    "                            print(json_data['response'], end='')\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(\"Error decoding JSON:\", line)\n",
    "        else:\n",
    "            print(f\"Failed to get response: {response.status_code} - {response.text}\")\n",
    "    \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return \"‚ùå Error: Cannot connect to Ollama. Is the container running?\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {str(e)}\"\n",
    "    \n",
    "test_llm('Introduce yourself. Be sarcastic.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Interactive Chat Interface\n",
    "\n",
    "Run the cell below to start chatting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets\n",
    "chat_output = Output(layout=Layout(height='400px', overflow_y='auto', border='1px solid #444', \n",
    "                                    padding='10px', background_color='#0e1117'))\n",
    "input_box = Textarea(\n",
    "    placeholder='Type your message here...',\n",
    "    layout=Layout(width='70%', height='60px')\n",
    ")\n",
    "send_button = Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    layout=Layout(width='15%', height='60px')\n",
    ")\n",
    "clear_button = Button(\n",
    "    description='Clear Chat',\n",
    "    button_style='warning',\n",
    "    layout=Layout(width='15%', height='60px')\n",
    ")\n",
    "status_label = HTMLWidget(\n",
    "    value='<p style=\"color: #888;\">Ready to chat! Type a message and click Send.</p>'\n",
    ")\n",
    "\n",
    "def display_chat_history():\n",
    "    \"\"\"Display all chat messages.\"\"\"\n",
    "    with chat_output:\n",
    "        clear_output()\n",
    "        for msg in chat_history:\n",
    "            display(HTML(format_chat_message(msg['role'], msg['content'], msg['timestamp'])))\n",
    "\n",
    "def on_send_click(b):\n",
    "    \"\"\"Handle send button click.\"\"\"\n",
    "    user_message = input_box.value.strip()\n",
    "    \n",
    "    if not user_message:\n",
    "        status_label.value = '<p style=\"color: orange;\">‚ö†Ô∏è Please enter a message</p>'\n",
    "        return\n",
    "    \n",
    "    # Clear input\n",
    "    input_box.value = ''\n",
    "    \n",
    "    # Add user message to history\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    chat_history.append({\n",
    "        'role': 'user',\n",
    "        'content': user_message,\n",
    "        'timestamp': timestamp\n",
    "    })\n",
    "    \n",
    "    # Display updated chat\n",
    "    display_chat_history()\n",
    "    \n",
    "    # Show loading status\n",
    "    status_label.value = '<p style=\"color: #4CAF50;\">üîÑ Thinking...</p>'\n",
    "    \n",
    "    # Get response from Ollama\n",
    "    response = send_message_to_ollama(user_message)\n",
    "    \n",
    "    # Add assistant response to history\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    chat_history.append({\n",
    "        'role': 'assistant',\n",
    "        'content': response,\n",
    "        'timestamp': timestamp\n",
    "    })\n",
    "    \n",
    "    # Display updated chat\n",
    "    display_chat_history()\n",
    "    \n",
    "    # Update status\n",
    "    if response.startswith('‚ùå'):\n",
    "        status_label.value = '<p style=\"color: red;\">Error occurred. Check connection.</p>'\n",
    "    else:\n",
    "        status_label.value = f'<p style=\"color: #4CAF50;\">‚úÖ Response received | Messages: {len(chat_history)}</p>'\n",
    "\n",
    "def on_clear_click(b):\n",
    "    \"\"\"Handle clear button click.\"\"\"\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    with chat_output:\n",
    "        clear_output()\n",
    "    status_label.value = '<p style=\"color: #888;\">Chat cleared. Ready for new conversation.</p>'\n",
    "\n",
    "# Attach event handlers\n",
    "send_button.on_click(on_send_click)\n",
    "clear_button.on_click(on_clear_click)\n",
    "\n",
    "# Allow Enter key to send (Shift+Enter for new line)\n",
    "def handle_input(change):\n",
    "    if '\\n' in change['new'] and not change['new'].endswith('\\n\\n'):\n",
    "        # Simple enter pressed\n",
    "        input_box.value = change['new'].replace('\\n', '')\n",
    "        on_send_click(None)\n",
    "\n",
    "# Layout\n",
    "input_row = HBox([input_box, send_button, clear_button], layout=Layout(width='100%'))\n",
    "chat_interface = VBox([\n",
    "    HTMLWidget(value='<h3 style=\"color: #4CAF50;\">üí¨ Chat with Mistral 7B</h3>'),\n",
    "    status_label,\n",
    "    chat_output,\n",
    "    HTMLWidget(value='<p style=\"color: #888; font-size: 0.9em; margin-top: 10px;\">'\n",
    "                     'Tip: Type your message and click Send or press Enter</p>'),\n",
    "    input_row\n",
    "], layout=Layout(width='100%', padding='20px', background_color='#1a1a1a', border_radius='10px'))\n",
    "\n",
    "# Display the interface\n",
    "display(chat_interface)\n",
    "\n",
    "print(\"\\nüéâ Chat interface ready! Start typing below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Chat Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View chat statistics\n",
    "print(f\"Total Messages: {len(chat_history)}\")\n",
    "print(f\"User Messages: {len([m for m in chat_history if m['role'] == 'user'])}\")\n",
    "print(f\"Assistant Messages: {len([m for m in chat_history if m['role'] == 'assistant'])}\")\n",
    "\n",
    "if chat_history:\n",
    "    print(f\"\\nFirst message: {chat_history[0]['timestamp']}\")\n",
    "    print(f\"Last message: {chat_history[-1]['timestamp']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
